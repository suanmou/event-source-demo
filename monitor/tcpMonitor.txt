import os
import json
import time
import signal
import threading
import socket
import sys
from http.server import BaseHTTPRequestHandler, HTTPServer
from typing import Dict, List, Tuple, Optional

# -------------------------- 配置项 --------------------------
# 监控的FIX端口列表
MONITOR_PORTS = set(map(int, os.getenv("FIX_MONITOR_PORTS", "9876,9877").split(",")))
# 持久化文件路径
PERSIST_FILE = os.getenv("FIX_PERSIST_FILE", "/tmp/fix_connection_history.json")
# 采集频率（秒）
COLLECT_INTERVAL = 1
# 刷盘频率（秒）
PERSIST_INTERVAL = 10
# HTTP服务端口
HTTP_PORT = 9090

# 历史数据清理配置
FIX_CLEAN_RETENTION_DAYS = int(os.getenv("FIX_CLEAN_RETENTION_DAYS", "7"))  # 保留最近7天
FIX_CLEAN_MAX_ENTRIES = int(os.getenv("FIX_CLEAN_MAX_ENTRIES", "100000"))  # 最多保留10万条（刷盘清理用）
FIX_CLEAN_INTERVAL = int(os.getenv("FIX_CLEAN_INTERVAL", 3600))  # 清理检查间隔（1小时）
FIX_LOAD_MAX_ENTRIES = int(os.getenv("FIX_LOAD_MAX_ENTRIES", "10000"))  # 加载时最多读取前10000条

# -------------------------- 常量定义 --------------------------
TCP_STATUS_MAP = {
    "01": "ESTABLISHED",
    "02": "SYN_SENT",
    "03": "SYN_RECV",
    "04": "FIN_WAIT1",
    "05": "FIN_WAIT2",
    "06": "TIME_WAIT",
    "07": "CLOSE",
    "08": "CLOSE_WAIT",
    "09": "LAST_ACK",
    "0A": "LISTEN",
    "0B": "CLOSING"
}

# -------------------------- 工具函数 --------------------------
def hex_to_ip(hex_str: str) -> str:
    bytes_list = [hex_str[i:i+2] for i in range(0, 8, 2)][::-1]
    return ".".join(str(int(b, 16)) for b in bytes_list)

def hex_to_port(hex_str: str) -> int:
    return int(hex_str, 16)

def parse_proc_net_tcp() -> List[Dict]:
    connections = []
    try:
        with open("/proc/net/tcp", "r") as f:
            lines = f.readlines()[1:]
            for line in lines:
                fields = line.strip().split()
                if len(fields) < 12:
                    continue
                sl = fields[0].strip(":")
                local_addr = fields[1].split(":")
                rem_addr = fields[2].split(":")
                st = fields[3]
                inode = fields[9]

                local_ip = hex_to_ip(local_addr[0])
                local_port = hex_to_port(local_addr[1])
                remote_ip = hex_to_ip(rem_addr[0])
                remote_port = hex_to_port(rem_addr[1])
                status = TCP_STATUS_MAP.get(st, "UNKNOWN")

                if local_port in MONITOR_PORTS and status == "ESTABLISHED":
                    connections.append({
                        "inode": inode,
                        "local_ip": local_ip,
                        "local_port": local_port,
                        "remote_ip": remote_ip,
                        "remote_port": remote_port,
                        "status": status,
                        "timestamp": time.time()
                    })
    except Exception as e:
        print(f"解析/proc/net/tcp失败: {e}", file=sys.stderr)
    return connections

# -------------------------- 监控核心类 --------------------------
class FixConnectionMonitor:
    def __init__(self):
        # 运行时数据
        self.current_connections: Dict[str, Dict] = {}
        self.historical_connections: List[Dict] = []
        self.total_connections: int = 0
        self.port_stats: Dict[int, int] = {}
        self.ip_stats: Dict[str, int] = {}

        # 线程锁（保护历史数据读写）
        self.data_lock = threading.Lock()
        # 最后一次清理时间
        self.last_clean_time = 0

        # 加载持久化数据（新增自动创建+加载截断逻辑）
        self.load_persist_data()

        # 线程控制
        self.running = True
        self.collect_thread: Optional[threading.Thread] = None
        self.persist_thread: Optional[threading.Thread] = None

    def load_persist_data(self):
        """加载持久化数据：自动创建空文件 + 仅读取前N条"""
        # 步骤1：检查文件是否存在，不存在则创建空文件
        if not os.path.exists(PERSIST_FILE):
            try:
                # 确保目录存在
                os.makedirs(os.path.dirname(PERSIST_FILE), exist_ok=True)
                # 写入空结构
                empty_data = {
                    "historical_connections": [],
                    "total_connections": 0
                }
                with open(PERSIST_FILE, "w") as f:
                    json.dump(empty_data, f, indent=2)
                print(f"持久化文件不存在，已自动创建空文件：{PERSIST_FILE}")
            except Exception as e:
                print(f"创建空持久化文件失败: {e}", file=sys.stderr)
                return

        # 步骤2：读取文件并截断前N条
        try:
            with open(PERSIST_FILE, "r") as f:
                data = json.load(f)
            
            with self.data_lock:
                # 读取历史连接并截断到指定条数（取最新的前N条，按断开时间降序）
                raw_historical = data.get("historical_connections", [])
                # 先排序（确保取最新的），再截断
                raw_historical.sort(key=lambda x: x.get("disconnect_time", 0), reverse=True)
                self.historical_connections = raw_historical[:FIX_LOAD_MAX_ENTRIES]
                
                # 累计连接数保留（不截断）
                self.total_connections = data.get("total_connections", 0)

            # 输出加载信息
            loaded_count = len(self.historical_connections)
            original_count = len(raw_historical)
            if original_count > loaded_count:
                print(f"加载历史数据：原文件有{original_count}条，仅读取前{FIX_LOAD_MAX_ENTRIES}条，实际加载{loaded_count}条")
            else:
                print(f"加载历史数据：共{loaded_count}条（未触发截断）")

            # 步骤3：加载后执行一次清理
            self.clean_old_connections(force=True)
            print(f"加载后清理完成，剩余历史连接数：{len(self.historical_connections)}")

        except Exception as e:
            print(f"加载持久化数据失败，初始化空数据: {e}", file=sys.stderr)
            with self.data_lock:
                self.historical_connections = []
                self.total_connections = 0

    def save_persist_data(self):
        """保存历史数据到文件（加锁保护）"""
        try:
            os.makedirs(os.path.dirname(PERSIST_FILE), exist_ok=True)
            with self.data_lock:
                with open(PERSIST_FILE, "w") as f:
                    json.dump({
                        "historical_connections": self.historical_connections,
                        "total_connections": self.total_connections
                    }, f, indent=2)
        except Exception as e:
            print(f"保存持久化数据失败: {e}", file=sys.stderr)

    def clean_old_connections(self, force: bool = False):
        """清理过期历史连接数据"""
        current_time = time.time()
        if not force and (current_time - self.last_clean_time) < FIX_CLEAN_INTERVAL:
            return

        with self.data_lock:
            original_count = len(self.historical_connections)
            if original_count == 0:
                self.last_clean_time = current_time
                return

            # 1. 按时间清理
            expire_timestamp = current_time - (FIX_CLEAN_RETENTION_DAYS * 86400)
            filtered_by_time = [
                conn for conn in self.historical_connections
                if conn.get("disconnect_time", 0) >= expire_timestamp
            ]

            # 2. 按数量清理
            if FIX_CLEAN_MAX_ENTRIES > 0 and len(filtered_by_time) > FIX_CLEAN_MAX_ENTRIES:
                filtered_by_time.sort(key=lambda x: x["disconnect_time"], reverse=True)
                filtered_final = filtered_by_time[:FIX_CLEAN_MAX_ENTRIES]
            else:
                filtered_final = filtered_by_time

            # 更新数据
            self.historical_connections = filtered_final
            cleaned_count = original_count - len(filtered_final)
            self.last_clean_time = current_time

            if cleaned_count > 0:
                print(f"清理历史连接数据：共清理{cleaned_count}条，剩余{len(filtered_final)}条")
            else:
                print("无过期历史连接数据需要清理")

    def collect_connections(self):
        """采集并更新连接状态"""
        while self.running:
            try:
                current_collect = parse_proc_net_tcp()
                current_inodes = {conn["inode"] for conn in current_collect}

                with self.data_lock:
                    # 新增/更新当前连接
                    for conn in current_collect:
                        inode = conn["inode"]
                        if inode not in self.current_connections:
                            conn["start_time"] = time.time()
                            self.current_connections[inode] = conn
                            self.total_connections += 1
                        else:
                            self.current_connections[inode].update(conn)

                    # 清理已断开的连接
                    disconnected_inodes = set(self.current_connections.keys()) - current_inodes
                    for inode in disconnected_inodes:
                        conn = self.current_connections.pop(inode)
                        end_time = time.time()
                        duration = end_time - conn["start_time"]
                        self.historical_connections.append({
                            "local_ip": conn["local_ip"],
                            "local_port": conn["local_port"],
                            "remote_ip": conn["remote_ip"],
                            "remote_port": conn["remote_port"],
                            "start_time": conn["start_time"],
                            "end_time": end_time,
                            "duration": round(duration, 2),
                            "disconnect_time": end_time
                        })

                # 更新端口/IP统计
                self.port_stats = {port: 0 for port in MONITOR_PORTS}
                self.ip_stats = {}
                for conn in self.current_connections.values():
                    port = conn["local_port"]
                    ip = conn["remote_ip"]
                    self.port_stats[port] += 1
                    self.ip_stats[ip] = self.ip_stats.get(ip, 0) + 1

            except Exception as e:
                print(f"采集连接数据失败: {e}", file=sys.stderr)
            finally:
                time.sleep(COLLECT_INTERVAL)

    def persist_loop(self):
        """定时刷盘 + 定时清理"""
        while self.running:
            self.save_persist_data()
            self.clean_old_connections()
            time.sleep(PERSIST_INTERVAL)

    def start(self):
        self.collect_thread = threading.Thread(target=self.collect_connections, daemon=True)
        self.collect_thread.start()
        self.persist_thread = threading.Thread(target=self.persist_loop, daemon=True)
        self.persist_thread.start()
        print(f"FIX连接监控启动：监控端口={MONITOR_PORTS}，HTTP端口={HTTP_PORT}，持久化文件={PERSIST_FILE}")
        print(f"清理策略：保留最近{FIX_CLEAN_RETENTION_DAYS}天 | 刷盘清理最多{FIX_CLEAN_MAX_ENTRIES}条 | 加载最多读取{FIX_LOAD_MAX_ENTRIES}条 | 检查间隔{FIX_CLEAN_INTERVAL}秒")

    def stop(self):
        self.running = False
        if self.collect_thread:
            self.collect_thread.join(timeout=2)
        if self.persist_thread:
            self.persist_thread.join(timeout=2)
        # 停止前强制清理+刷盘
        self.clean_old_connections(force=True)
        self.save_persist_data()
        print("FIX连接监控已停止，数据已保存并清理")

# -------------------------- HTTP服务 --------------------------
class FixMonitorHandler(BaseHTTPRequestHandler):
    monitor: FixConnectionMonitor = None

    def do_GET(self):
        if self.path == "/metrics":
            self.handle_metrics()
        elif self.path == "/connections":
            self.handle_connections()
        else:
            self.send_response(404)
            self.end_headers()
            self.wfile.write(b"Not Found")

    def handle_metrics(self):
        self.send_response(200)
        self.send_header("Content-Type", "text/plain; version=0.0.4")
        self.end_headers()

        metrics = []
        for inode, conn in self.monitor.current_connections.items():
            labels = f'local_port="{conn["local_port"]}",remote_ip="{conn["remote_ip"]}"'
            metrics.append(f'fix_connections_current{{{labels}}} 1')

        metrics.append(f'fix_connections_total {self.monitor.total_connections}')

        for port, count in self.monitor.port_stats.items():
            metrics.append(f'fix_port_connections{{port="{port}"}} {count}')

        durations = [conn["duration"] for conn in self.monitor.historical_connections]
        if durations:
            p50 = sorted(durations)[int(len(durations)*0.5)] if durations else 0
            p95 = sorted(durations)[int(len(durations)*0.95)] if durations else 0
            p99 = sorted(durations)[int(len(durations)*0.99)] if durations else 0
            metrics.append(f'fix_connection_duration_seconds_summary{{quantile="0.5"}} {round(p50, 2)}')
            metrics.append(f'fix_connection_duration_seconds_summary{{quantile="0.95"}} {round(p95, 2)}')
            metrics.append(f'fix_connection_duration_seconds_summary{{quantile="0.99"}} {round(p99, 2)}')
            metrics.append(f'fix_connection_duration_seconds_count {len(durations)}')
            metrics.append(f'fix_connection_duration_seconds_sum {round(sum(durations), 2)}')

        self.wfile.write("\n".join(metrics).encode("utf-8"))

    def handle_connections(self):
        self.send_response(200)
        self.send_header("Content-Type", "application/json")
        self.end_headers()

        current_conns = []
        for conn in self.monitor.current_connections.values():
            current_conns.append({
                "local_ip": conn["local_ip"],
                "local_port": conn["local_port"],
                "remote_ip": conn["remote_ip"],
                "remote_port": conn["remote_port"],
                "start_time": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(conn["start_time"])),
                "duration_seconds": round(time.time() - conn["start_time"], 2)
            })

        response = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
            "total_current": len(current_conns),
            "connections": current_conns
        }
        self.wfile.write(json.dumps(response, indent=2).encode("utf-8"))

    def log_message(self, format, *args):
        return

# -------------------------- 主程序 --------------------------
def main():
    monitor = FixConnectionMonitor()
    FixMonitorHandler.monitor = monitor

    http_server = HTTPServer(("", HTTP_PORT), FixMonitorHandler)
    http_thread = threading.Thread(target=http_server.serve_forever, daemon=True)
    http_thread.start()

    def signal_handler(signum, frame):
        print(f"\n收到退出信号 {signum}")
        monitor.stop()
        http_server.shutdown()
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    monitor.start()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        signal_handler(signal.SIGINT, None)

if __name__ == "__main__":
    main()